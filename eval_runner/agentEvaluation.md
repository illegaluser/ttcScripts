# DSCORE-TTC: ì™¸ë¶€ AI ì—ì´ì „íŠ¸ í‰ê°€ ì‹œìŠ¤í…œ E2E í†µí•© êµ¬ì¶• ë§ˆìŠ¤í„° ê°€ì´ë“œ (ìµœì¢… ì™„ì„±ë³¸)

## ğŸ“– ì œ1ì¥. 7ëŒ€ ì¸¡ì • ì§€í‘œ(Metrics) ë° í”„ë ˆì„ì›Œí¬ ë§¤í•‘ ì•ˆë‚´

ì‹œìŠ¤í…œì€ ìì› ë‚­ë¹„ë¥¼ ë§‰ê³  í‰ê°€ ì‹ ë¢°ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ 3ë‹¨ê³„(Fail-Fast â” ê³¼ì—… ê²€ì‚¬ â” ë¬¸ë§¥ í‰ê°€)ë¡œ ë‚˜ëˆ„ì–´ ì´ 7ê°€ì§€ ì§€í‘œë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

| ê²€ì¦ ë‹¨ê³„ | ì¸¡ì • ì§€í‘œ (Metric) | ë‹´ë‹¹ í”„ë ˆì„ì›Œí¬ ë° ì¸¡ì • ì›ë¦¬ | ì½”ë“œ ìœ„ì¹˜ |
| --- | --- | --- | --- |
| **1. Fail-Fast**<br>

<br>(ì¦‰ì‹œ ì°¨ë‹¨) | **â‘  Policy Violation**<br>

<br>(ë³´ì•ˆ/ê¸ˆì¹™ì–´ ìœ„ë°˜) | **[Promptfoo]**<br>

<br>AIì˜ ì‘ë‹µì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•œ ë’¤, ì™¸ì¥ ë„êµ¬ì¸ Promptfooë¥¼ CLIë¡œ í˜¸ì¶œí•˜ì—¬ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ë‚˜ API Key ë“± ì •ì˜ëœ ì •ê·œì‹ íŒ¨í„´ì´ ë°œê²¬ë˜ë©´ ì¦‰ì‹œ ë¶ˆí•©ê²©ì‹œí‚µë‹ˆë‹¤. | `test_runner.py`ì˜<br>

<br>`_promptfoo_check` |
|  | **â‘¡ Format Compliance**<br>

<br>(ì‘ë‹µ ê·œê²© ì¤€ìˆ˜) | **[jsonschema (Python)]**<br>

<br>ëŒ€ìƒ AIê°€ APIì¼ ê²½ìš°, ë°˜í™˜í•œ JSON ë°ì´í„°ê°€ ìš°ë¦¬ê°€ ìš”êµ¬í•œ í•„ìˆ˜ í˜•íƒœ(ì˜ˆ: `answer` í‚¤ í¬í•¨)ë¥¼ ê°–ì¶”ì—ˆëŠ”ì§€ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê²€ì‚¬í•©ë‹ˆë‹¤. | `test_runner.py`ì˜<br>

<br>`_schema_check` |
| **2. ê³¼ì—… ê²€ì‚¬**<br>

<br>(Agent ì „ìš©) | **â‘¢ Task Completion**<br>

<br>(ì§€ì‹œ ê³¼ì—… ë‹¬ì„±ë„) | **[Python Custom Logic]**<br>

<br>ëŒ€ìƒ AIê°€ ì¸í”„ë¼ë¥¼ ì œì–´í•˜ëŠ” Agentì¼ ê²½ìš°, ìƒíƒœ ì½”ë“œ(`status_code=200`)ë‚˜ íŠ¹ì • ë¬¸ìì—´(`raw~r/ì™„ë£Œ/`)ì„ ë°˜í™˜í–ˆëŠ”ì§€ ìì²´ ì •ê·œì‹ íŒŒì„œë¡œ ë³µí•© ê²€ì‚¬í•©ë‹ˆë‹¤. | `test_runner.py`ì˜<br>

<br>`_evaluate_agent_criteria` |
| **3. ì‹¬ì¸µ í‰ê°€**<br>

<br>(ë¬¸ë§¥ ì±„ì ) | **â‘£ Answer Relevancy**<br>

<br>(ë™ë¬¸ì„œë‹µ ì—¬ë¶€) | **[DeepEval + Ollama]**<br>

<br>DeepEval í”„ë ˆì„ì›Œí¬ê°€ ë¡œì»¬ LLM(Ollama)ì„ ì‹¬íŒê´€ìœ¼ë¡œ ê¸°ìš©í•˜ì—¬, AIì˜ ëŒ€ë‹µì´ ì§ˆë¬¸ ì˜ë„ì— ë¶€í•©í•˜ëŠ”ì§€ 0~1ì  ì‚¬ì´ì˜ ì‹¤ìˆ˜ë¡œ ì •ë°€ ì±„ì í•©ë‹ˆë‹¤. | `test_runner.py`ì˜<br>

<br>`AnswerRelevancyMetric` |
|  | **â‘¤ Faithfulness**<br>

<br>(í™˜ê°/ê±°ì§“ë§ ì—¬ë¶€) | **[DeepEval + Ollama]**<br>

<br>ë‹µë³€ ë‚´ìš©ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê²€ìƒ‰ëœ ì›ë¬¸(`docs`)ì— ëª…ì‹œëœ ì‚¬ì‹¤ì¸ì§€, ì§€ì–´ë‚¸ ë§ì¸ì§€ ì±„ì í•©ë‹ˆë‹¤. (â€» ëŒ€ìƒ ì‹œìŠ¤í…œì´ ì›ë¬¸ì„ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤íƒ ë°©ì§€ë¥¼ ìœ„í•´ ìƒëµí•©ë‹ˆë‹¤.) | `test_runner.py`ì˜<br>

<br>`FaithfulnessMetric` |
|  | **â‘¥ Contextual Recall**<br>

<br>(ì •ë³´ ê²€ìƒ‰ë ¥) | **[DeepEval + Ollama]**<br>

<br>ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ AIê°€ ì¶©ë¶„í•˜ê³  ì˜¬ë°”ë¥¸ ì •ë³´(ì›ë¬¸)ë¥¼ ê²€ìƒ‰í•´ ì™”ëŠ”ì§€ ì±„ì í•©ë‹ˆë‹¤. (â€» ê²€ìƒ‰ ì›ë¬¸ í™•ì¸ì´ ê°€ëŠ¥í•œ API ëª¨ë“œ ì „ìš©ì…ë‹ˆë‹¤.) | `test_runner.py`ì˜<br>

<br>`ContextualRecallMetric` |
| **4. ìš´ì˜ ê´€ì œ** | **â‘¦ Latency**<br>

<br>(ì‘ë‹µ ì†Œìš” ì‹œê°„) | **[Python `time` + Langfuse]**<br>

<br>ì§ˆë¬¸ì„ ë˜ì§„ ì‹œì ë¶€í„° ë‹µë³€ ìˆ˜ì‹ (ë˜ëŠ” í™”ë©´ ë Œë”ë§) ì™„ë£Œê¹Œì§€ì˜ ì²´ê° ì‹œê°„ì„ ë°€ë¦¬ì´ˆ(ms)ë¡œ ì¬ê³  Langfuseì— ì „ì†¡í•©ë‹ˆë‹¤. | `adapters/` ë‚´ë¶€ì˜<br>

<br>íƒ€ì´ë¨¸ ë³€ìˆ˜ |

---

## ğŸ“– ì œ2ì¥. ìŠ¤í¬ë¦½íŠ¸ ê°„ ì—°ê´€ê´€ê³„ ë° ë°ì´í„° í”Œë¡œìš° (Architecture Flow)

í‰ê°€ ì‹œìŠ¤í…œì˜ ì½”ë“œë“¤ì€ ê°ìì˜ ëª…í™•í•œ ì—­í• ì„ ê°€ì§€ê³  ì„œë¡œ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ìœ¼ë©° í­í¬ìˆ˜(Waterfall)ì²˜ëŸ¼ ì‘ë™í•©ë‹ˆë‹¤.

1. **`Jenkins Pipeline` (ìš´ì˜ì ì¸í„°í˜ì´ìŠ¤)**: ìš´ì˜ìê°€ í¼ì— ì…ë ¥í•œ íƒ€ê²Ÿ ì£¼ì†Œ, ë°©ì‹(http/ui_chat), ì¸ì¦ í‚¤, ì‹œí—˜ì§€(CSV)ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¸íŒ…í•˜ê³  ì´ê´„ í‰ê°€ê´€ì„ ê¹¨ì›ë‹ˆë‹¤.
2. **`test_runner.py` (ì´ê´„ í‰ê°€ê´€)**: ì‹œìŠ¤í…œì˜ ì§€íœ˜ì†Œì…ë‹ˆë‹¤. ì‹œí—˜ì§€ë¥¼ í•œ ì¤„ì”© ì½ì€ ë’¤, êµí™˜ê¸°(`registry.py`)ì— í˜„ì¬ ë°©ì‹ì— ë§ëŠ” í†µì‹ ì›ì„ íŒŒê²¬í•´ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤.
3. **`registry.py` (ì–´ëŒ‘í„° êµí™˜ê¸°)**: `test_runner.py`ì˜ ìš”ì²­ì„ ë°›ì•„, API ë°©ì‹ì´ë©´ `http_adapter.py`ë¥¼, ì›¹ ë°©ì‹ì´ë©´ `playwright_adapter.py`ë¥¼ ë§¤ì¹­í•´ ì¤ë‹ˆë‹¤.
4. **`http_adapter.py` / `playwright_adapter.py` (í†µì‹ ì›)**: ì‹¤ì œ ëŒ€ìƒ AIì— ì ‘ì†í•´ ì§ˆë¬¸ì„ ë˜ì§€ê³  ë‹µë³€ì„ ë°›ì•„ì˜µë‹ˆë‹¤. ì´ë•Œ ë°©ì‹ì´ ë‹¬ë¼ë„ ë°˜ë“œì‹œ `base.py`ì— ì •ì˜ëœ **í‘œì¤€ ë°”êµ¬ë‹ˆ(UniversalEvalOutput)** ê·œê²©ì— ë°ì´í„°ë¥¼ ë‹´ì•„ í‰ê°€ê´€ì—ê²Œ ì œì¶œí•©ë‹ˆë‹¤.
5. **`configs/security.yaml` & `schema.json` (ê²€ë¬¸ì†Œ)**: í†µì‹ ì›ì´ ê°€ì ¸ì˜¨ ë‹µë³€ ë°”êµ¬ë‹ˆë¥¼ í‰ê°€ê´€ì´ 1ì°¨ë¡œ ê²€ì‚¬í•  ë•Œ ì“°ëŠ” ê·œì¹™ ë¬¸ì„œì…ë‹ˆë‹¤.
6. **`DeepEval` & `Ollama` (ì‹¬íŒê´€)**: 1ì°¨ ê²€ì‚¬ë¥¼ í†µê³¼í•˜ë©´, í‰ê°€ê´€ì´ ë¡œì»¬ LLMì„ í˜¸ì¶œí•´ ë¬¸ë§¥ì˜ ì§ˆ(í™˜ê°, ë™ë¬¸ì„œë‹µ)ì„ ì±„ì ì‹œí‚µë‹ˆë‹¤.
7. **`Langfuse` (ê´€ì œíƒ‘)**: ëª¨ë“  ê³¼ì •(í†µì‹  ì†ë„, ì—ëŸ¬, ì ìˆ˜, ê°ì  ì´ìœ )ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬ë°›ì•„ 90ì¼ê°„ ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.

---

## ì œ3ì¥. Jenkins Credentials ì‚¬ì „ ë“±ë¡ (ë³´ì•ˆ)

íŒŒì´í”„ë¼ì¸ ì†ŒìŠ¤ ì½”ë“œì— Langfuse API Keyë¥¼ í•˜ë“œì½”ë”©í•˜ë©´ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œìƒí•©ë‹ˆë‹¤. Jenkinsì˜ ì•”í˜¸í™” ì €ì¥ì†Œë¥¼ ì´ìš©í•©ë‹ˆë‹¤.

1. ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8080` (Jenkins)ì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤.
2. **[Jenkins ê´€ë¦¬(Manage Jenkins)]** â” **[Credentials]** â” **[System]** â” **[Global credentials (unrestricted)]**ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.
3. ìš°ì¸¡ ìƒë‹¨ **[Add Credentials]** í´ë¦­ â” Kindë¥¼ **[Secret text]**ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
4. Secretì— Langfuse **Public Key**(`pk-lf-...`)ë¥¼, IDì— `langfuse-public-key`ë¥¼ ì…ë ¥í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
5. ë‹¤ì‹œ **[Add Credentials]** í´ë¦­ â” Secretì— **Secret Key**(`sk-lf-...`)ë¥¼, IDì— `langfuse-secret-key`ë¥¼ ì…ë ¥í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

---

## ì œ4ì¥. í˜¸ìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬ ì„¸íŒ… ë° Docker ì¸í”„ë¼ ë³‘í•© êµ¬ì„±

ê¸°ì¡´ DSCORE-TTCì˜ DevOps ë° ì§€ì‹ ê´€ë¦¬ ì¸í”„ë¼ë¥¼ ì „í˜€ ê±´ë“œë¦¬ì§€ ì•Šê³ , í•„ìš”í•œ íŒ¨í‚¤ì§€ì™€ ì„œë¹„ìŠ¤ë§Œ ì •í™•í•˜ê²Œ ë§ë¶™ì´ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

### 4.1 í˜¸ìŠ¤íŠ¸ ë¬¼ë¦¬ ë””ë ‰í„°ë¦¬ ìƒì„±

í„°ë¯¸ë„ì„ ì—´ê³  `<PROJECT_ROOT>`ì—ì„œ ê¸°ì¡´ êµ¬ì¡°ì— í‰ê°€ìš© í´ë”ë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```bash
# 1. í‰ê°€ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ ë° ì„¤ì • íŒŒì¼ í´ë”
mkdir -p data/jenkins/scripts/eval_runner/adapters
mkdir -p data/jenkins/scripts/eval_runner/configs
mkdir -p data/jenkins/scripts/eval_runner/tests

# 2. í‰ê°€ ê¸°ì¤€ ì‹œí—˜ì§€ ë° ê²°ê³¼ ë¦¬í¬íŠ¸ í´ë”
mkdir -p data/knowledges/eval/data
mkdir -p data/knowledges/eval/reports

# 3. Langfuse ê´€ì œíƒ‘ ë°ì´í„°ë² ì´ìŠ¤ ë³´ì¡´ìš© í´ë”
mkdir -p data/postgres-langfuse

```

### 4.2 `Dockerfile.jenkins` (ê¸°ì¡´ êµ¬ì„± + ì‹ ê·œ í‰ê°€ ë„êµ¬ í†µí•©)

ê¸°ì¡´ íŒŒì¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, `nodejs`, `npm`, `deepeval`, `langfuse` ë“±ì„ ë³‘í•©í•œ ì™„ì „ë³¸ì…ë‹ˆë‹¤. íŒŒì¼ì„ ë®ì–´ì“°ì‹­ì‹œì˜¤.

```dockerfile
# DSCORE-TTC í†µí•© Jenkins ì´ë¯¸ì§€ (AI ì—ì´ì „íŠ¸ í‰ê°€ ë„êµ¬ í¬í•¨ í™•ì¥íŒ)
FROM jenkins/jenkins:lts-jdk21
USER root

# 1. ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (ê¸°ì¡´ + Promptfooìš© nodejs/npm ì¶”ê°€)
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv \
    curl jq \
    libgtk-3-0 libasound2 libdbus-glib-1-2 libx11-xcb1 \
    poppler-utils \
    libreoffice-impress \
    nodejs npm \
    && rm -rf /var/lib/apt/lists/*

# 2. í•„ìˆ˜ íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì¼ê´„ ì„¤ì¹˜
# ê¸°ì¡´ ì§€ì‹ê´€ë¦¬(pymupdf, crawl4ai ë“±) ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì‹ ê·œ í‰ê°€ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í•¨ê»˜ ì„¤ì¹˜
RUN pip3 install --no-cache-dir --break-system-packages \
    requests tenacity beautifulsoup4 lxml html2text \
    pypdf pdf2image pillow python-docx python-pptx pandas openpyxl pymupdf \
    crawl4ai playwright ollama \
    deepeval==1.3.5 pytest==8.0.0 pytest-xdist==3.5.0 \
    jsonschema==4.21.1 langfuse==2.15.0 jsonpath-ng==1.6.1

# 3. Playwright ë¸Œë¼ìš°ì € ì—”ì§„ ì„¤ì¹˜
RUN python3 -m playwright install --with-deps chromium

# 4. ì •ì  ë³´ì•ˆ ë¶„ì„ìš© Promptfoo ê¸€ë¡œë²Œ ì„¤ì¹˜
RUN npm install -g promptfoo@0.50.0

ENV TZ=Asia/Seoul

RUN mkdir -p /var/jenkins_home/scripts \
    /var/jenkins_home/knowledges \
    && chown -R jenkins:jenkins /var/jenkins_home

USER jenkins

```

### 4.3 `docker-compose.yaml` (ê¸°ì¡´ êµ¬ì„± + Langfuse ì„œë²„ í†µí•©)

ê¸°ì¡´ì˜ SonarQubeì™€ GitLab êµ¬ì„±ì„ ëª¨ë‘ ìœ ì§€í•œ ì±„ Langfuse ìŠ¤íƒë§Œ ì¶”ê°€í•œ ì™„ì „ë³¸ì…ë‹ˆë‹¤. íŒŒì¼ì„ ë®ì–´ì“°ì‹­ì‹œì˜¤.

```yaml
networks:
  devops-net:
    external: true

services:
  # ==========================================
  # [ê¸°ì¡´] SonarQube & GitLab Stack
  # ==========================================
  postgres-sonar:
    image: postgres:15-alpine
    container_name: postgres-sonar
    environment:
      POSTGRES_USER: sonar
      POSTGRES_PASSWORD: sonarpassword
      POSTGRES_DB: sonar
    volumes:
      - ./data/postgres-sonar:/var/lib/postgresql/data
    networks:
      - devops-net
    restart: unless-stopped

  sonarqube:
    image: sonarqube:community
    container_name: sonarqube
    depends_on:
      - postgres-sonar
    environment:
      SONAR_JDBC_URL: jdbc:postgresql://postgres-sonar:5432/sonar
      SONAR_JDBC_USERNAME: sonar
      SONAR_JDBC_PASSWORD: sonarpassword
      SONAR_ES_BOOTSTRAP_CHECKS_DISABLE: true
    ports:
      - "9000:9000"
    volumes:
      - ./data/sonarqube/data:/opt/sonarqube/data
      - ./data/sonarqube/extensions:/opt/sonarqube/extensions
      - ./data/sonarqube/logs:/opt/sonarqube/logs
    networks:
      - devops-net
    restart: unless-stopped

  gitlab:
    image: gitlab/gitlab-ce:latest
    container_name: gitlab
    hostname: gitlab.local
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://localhost:8929'
        gitlab_rails['gitlab_shell_ssh_port'] = 2224
        puma['worker_processes'] = 2
        sidekiq['concurrency'] = 5
        prometheus_monitoring['enable'] = false
        gitlab_rails['time_zone'] = 'Asia/Seoul'
    ports:
      - "8929:8929"
      - "2224:22"
    volumes:
      - ./data/gitlab/config:/etc/gitlab
      - ./data/gitlab/logs:/var/log/gitlab
      - ./data/gitlab/data:/var/opt/gitlab
    networks:
      - devops-net
    shm_size: "256m"
    restart: unless-stopped

  # ==========================================
  # [ì‹ ê·œ] Langfuse AI í‰ê°€ ê´€ì œ ìŠ¤íƒ
  # ==========================================
  db-langfuse:
    image: postgres:15-alpine
    container_name: db-langfuse
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgrespassword
      POSTGRES_DB: langfuse
    volumes:
      - ./data/postgres-langfuse:/var/lib/postgresql/data
    networks:
      - devops-net
    restart: unless-stopped

  langfuse-server:
    image: langfuse/langfuse:latest
    container_name: langfuse-server
    depends_on:
      - db-langfuse
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://postgres:postgrespassword@db-langfuse:5432/langfuse
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=dscore_super_secret_key
      - TELEMETRY_ENABLED=false
      - TRACE_RETENTION_DAYS=90 # 90ì¼ ê²½ê³¼ ë¡œê·¸ ìë™ ì‚­ì œ (ë¬´í•œ ì¦ì‹ ë°©ì§€)
    networks:
      - devops-net
    restart: unless-stopped

  # ==========================================
  # [ìˆ˜ì •] í†µí•© Jenkins (ë³¼ë¥¨ ë§ˆìš´íŠ¸ ìœ ì§€)
  # ==========================================
  jenkins:
    build:
      context: .
      dockerfile: Dockerfile.jenkins
    container_name: jenkins
    user: root
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - ./data/jenkins:/var/jenkins_home
      - ./data/jenkins/scripts:/var/jenkins_home/scripts
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/knowledges:/var/knowledges
    networks:
      - devops-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

```

**ì‹¤í–‰ ëª…ë ¹:** `<PROJECT_ROOT>`ì—ì„œ `docker compose up -d --build` ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸í”„ë¼ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤.

---

## ì œ5ì¥. íŒŒì´ì¬ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (ìƒì„¸ ì£¼ì„ ì™„ë¹„)

ì´ˆë³´ìë„ ì½”ë“œì˜ íë¦„ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸í•œ ì£¼ì„ì„ í¬í•¨í•œ 7ê°œì˜ íŒŒì´ì¬ ë° ì„¤ì • íŒŒì¼ì„ ê° ê²½ë¡œì— ìƒì„±í•©ë‹ˆë‹¤.

### 5.1 ì–´ëŒ‘í„° ë ˆì´ì–´ (`adapters/` í´ë”)

**â‘  `base.py` (ë°ì´í„° í‘œì¤€ ê·œê²©ì„œ)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/adapters/base.py`

```python
from dataclasses import dataclass, field
from typing import List, Optional

@dataclass
class UniversalEvalOutput:
    """
    API, UI ë“± í†µì‹  ë°©ì‹ì´ ë‹¬ë¼ë„ ëª¨ë“  ê²°ê³¼ë¥¼ ì´ ë°”êµ¬ë‹ˆì— ë™ì¼í•œ í˜•íƒœë¡œ ë‹´ìŠµë‹ˆë‹¤.
    í‰ê°€ê´€ì€ ì´ ë°”êµ¬ë‹ˆì˜ í˜•íƒœë§Œ ë³´ê³  ì±„ì ì„ ì§„í–‰í•©ë‹ˆë‹¤.
    """
    input: str                          # ì‚¬ìš©ìì˜ ì§ˆë¬¸
    actual_output: str                  # AIì˜ ìµœì¢… ë‹µë³€
    retrieval_context: List[str] = field(default_factory=list) # RAG ë´‡ì´ ì°¸ê³ í•œ ì›ë¬¸
    http_status: int = 0                # ìƒíƒœ ì½”ë“œ (200=ì •ìƒ)
    raw_response: str = ""              # íŒŒì‹± ì „ ì›ë³¸ ì‘ë‹µ ë°ì´í„° (ë³´ì•ˆ ê²€ì‚¬ìš©)
    error: Optional[str] = None         # í†µì‹  ì—ëŸ¬ ë©”ì‹œì§€
    latency_ms: int = 0                 # ì§ˆë¬¸ë¶€í„° ë‹µë³€ ìˆ˜ì‹ ê¹Œì§€ ê±¸ë¦° ë°€ë¦¬ì´ˆ ì‹œê°„

    def to_dict(self):
        # Langfuse ì „ì†¡ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ë³€í™˜
        return {"input": self.input, "actual_output": self.actual_output, "latency_ms": self.latency_ms, "error": self.error}

class BaseAdapter:
    """í†µì‹ ì›ë“¤ì˜ ë¼ˆëŒ€ í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    def __init__(self, target_url: str):
        self.target_url = target_url

    def invoke(self, input_text: str, **kwargs) -> UniversalEvalOutput:
        raise NotImplementedError

```

**â‘¡ `http_adapter.py` (API í†µì‹  ë° ë™ì  íŒŒì‹±)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/adapters/http_adapter.py`

```python
import time, os, requests
import jsonpath_ng.ext as jp # ì¤‘ì²©ëœ JSON íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬
from .base import BaseAdapter, UniversalEvalOutput

class GenericHttpAdapter(BaseAdapter):
    """ëŒ€ìƒ AIê°€ API í˜•íƒœì¼ ë•Œ ì‘ë™í•˜ë©°, ì¸ì¦ í—¤ë”ì™€ ë™ì  JSON Pathë¥¼ ì§€ì›í•©ë‹ˆë‹¤."""
    def invoke(self, input_text: str, **kwargs) -> UniversalEvalOutput:
        start_time = time.time()
        
        payload = {"query": input_text, "user": "eval-runner"}
        headers = {"Content-Type": "application/json"}
        
        # ì™¸ë¶€ ì‹œìŠ¤í…œì´ í† í°ì„ ìš”êµ¬í•  ê²½ìš° í™˜ê²½ ë³€ìˆ˜ì—ì„œ êº¼ë‚´ í—¤ë”ì— ì£¼ì…í•©ë‹ˆë‹¤.
        auth_header = os.environ.get("TARGET_AUTH_HEADER")
        if auth_header: 
            headers["Authorization"] = auth_header
        
        try:
            res = requests.post(self.target_url, json=payload, headers=headers, timeout=60)
            lat_ms = int((time.time() - start_time) * 1000)
            data = res.json() if res.status_code == 200 else {}
            
            actual_out = ""
            
            # íŒŒë¼ë¯¸í„°ë¡œ ë°›ì€ JSON Path(ì˜ˆ: $.result.data)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ê¸ì–´ì˜µë‹ˆë‹¤.
            path_expr = os.environ.get("RESPONSE_JSON_PATH", "$.answer")
            try:
                match = jp.parse(path_expr).find(data)
                if match: 
                    actual_out = match[0].value
            except: 
                pass
            
            # ë™ì  íŒŒì‹±ì— ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
            if not actual_out:
                actual_out = data.get("answer", data.get("response", data.get("text", "")))
            
            docs = data.get("docs", [])
            if isinstance(docs, str): 
                docs = [docs]

            return UniversalEvalOutput(
                input=input_text, actual_output=str(actual_out), retrieval_context=[str(c) for c in docs],
                http_status=res.status_code, raw_response=res.text, latency_ms=lat_ms, 
                error=f"HTTP {res.status_code}" if res.status_code >= 400 else None
            )

        except Exception as e:
            return UniversalEvalOutput(input=input_text, actual_output="", error=str(e), latency_ms=int((time.time() - start_time) * 1000))

```

**â‘¢ `playwright_adapter.py` (ì›¹ ìŠ¤í¬ë˜í•‘ ë° ìê°€ ì¹˜ìœ )**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/adapters/playwright_adapter.py`

```python
import time, os
from playwright.sync_api import sync_playwright
from openai import OpenAI
from .base import BaseAdapter, UniversalEvalOutput

class PlaywrightChatbotAdapter(BaseAdapter):
    """ì›¹ í™”ë©´ì— ì ‘ì†í•˜ì—¬ íƒ€ì´í•‘í•˜ê³  ë‹µë³€ì„ ê¸ì–´ì˜µë‹ˆë‹¤."""
    def invoke(self, input_text: str, **kwargs) -> UniversalEvalOutput:
        lat_ms, actual_out, error_msg = 0, "", None

        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            
            try:
                page.goto(self.target_url, wait_until="domcontentloaded", timeout=30000)
                page.get_by_placeholder("ì§ˆë¬¸", exact=False).first.fill(input_text)
                
                start_time = time.time()
                page.keyboard.press("Enter")
                
                # API í˜¸ì¶œì´ ë©ˆì¶”ëŠ” networkidle ìƒíƒœê¹Œì§€ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ëŒ€ê¸°í•©ë‹ˆë‹¤.
                page.wait_for_load_state("networkidle", timeout=15000)
                page.wait_for_timeout(2000) # íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ ì¶”ê°€ ëŒ€ê¸°
                
                try:
                    # 1ì°¨ ì‹œë„: ì›¹ í‘œì¤€ ë¡œê·¸ íƒœê·¸ íƒìƒ‰
                    actual_out = page.get_by_role("log").last.inner_text(timeout=3000)
                except:
                    # 2ì°¨ ì‹œë„: í™”ë©´ ì „ì²´ë¥¼ ê¸ì–´ ë¡œì»¬ LLMì—ê²Œ ì •ì œ(Self-Healing)ë¥¼ ì§€ì‹œí•©ë‹ˆë‹¤.
                    vis = page.locator("body").inner_text()
                    cli = OpenAI(base_url=f"{os.environ.get('OLLAMA_BASE_URL')}/v1", api_key="ollama")
                    prompt = f"ì§ˆë¬¸ '{input_text}'ì— ëŒ€í•œ ë‹µë³€ë§Œ ì¶”ì¶œí•´. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.\n[í™”ë©´]\n{vis}"
                    res = cli.chat.completions.create(model="qwen3-coder:30b", messages=[{"role": "user", "content": prompt}])
                    extracted = res.choices[0].message.content.strip()
                    
                    # LLMì´ ë„ˆë¬´ ë§ì€ HTMLì„ ë±‰ìœ¼ë©´ ë°ì´í„° ì˜¤ì—¼ìœ¼ë¡œ ê°„ì£¼í•´ ì‹¤íŒ¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.
                    if len(extracted) > 2000 or "<html" in extracted.lower():
                        raise RuntimeError("ìê°€ ì¹˜ìœ  ì‹¤íŒ¨: ë°ì´í„° ì˜¤ì—¼ ê°ì§€")
                    actual_out = extracted
                
                lat_ms = int((time.time() - start_time) * 1000)

            except Exception as e:
                error_msg = f"UI ì¡°ì‘ ì‹¤íŒ¨: {str(e)}"
                lat_ms = int((time.time() - start_time) * 1000)
            finally:
                browser.close()

        return UniversalEvalOutput(input=input_text, actual_output=actual_out, http_status=200, raw_response=actual_out, latency_ms=lat_ms, error=error_msg)

```

**â‘£ `registry.py` (ì–´ëŒ‘í„° êµí™˜ê¸°)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/adapters/registry.py`

```python
from .http_adapter import GenericHttpAdapter
from .playwright_adapter import PlaywrightChatbotAdapter

class AdapterRegistry:
    @classmethod
    def get_instance(cls, name: str, target_url: str):
        adapter_class = {"http": GenericHttpAdapter, "ui_chat": PlaywrightChatbotAdapter}.get(name, GenericHttpAdapter)
        return adapter_class(target_url)

```

### 5.2 ê²€ì¦ ë£°ì…‹ íŒŒì¼ (`configs/` í´ë”)

**â‘¤ `security.yaml` (ê¸ˆì¹™ì–´ ê·œì¹™)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/configs/security.yaml`

```yaml
prompts: [ "{{ prompt }}" ]
providers: [ "echo" ]
tests:
  - vars: { name: "pii_check" }
    assert: [ { type: not-contains-regex, value: "\\b\\d{6}-\\d{7}\\b" } ]

```

**â‘¥ `schema.json` (ì‘ë‹µ êµ¬ì¡° ê·œì¹™)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/configs/schema.json`

```json
{"type": "object"}

```

### 5.3 ì´ê´„ í‰ê°€ê´€ (`tests/test_runner.py`)

**â‘¦ `test_runner.py` (í‰ê°€ ë° Langfuse ê¸°ë¡ ë¡œì§)**

* **ê²½ë¡œ:** `./data/jenkins/scripts/eval_runner/tests/test_runner.py`

```python
import os, json, re, tempfile, subprocess, pytest, pandas as pd, uuid
from jsonschema import validate
from deepeval import assert_test
from deepeval.test_case import LLMTestCase
from deepeval.metrics import FaithfulnessMetric, AnswerRelevancyMetric, ContextualRecallMetric
from deepeval.models.gpt_model import GPTModel
from adapters.registry import AdapterRegistry
from langfuse import Langfuse

TARGET_URL = os.environ.get("TARGET_URL")
TARGET_TYPE = os.environ.get("TARGET_TYPE", "http")
RUN_ID = os.environ.get("BUILD_TAG", "Manual-Run")

langfuse = Langfuse(public_key=os.environ.get("LANGFUSE_PUBLIC_KEY"), secret_key=os.environ.get("LANGFUSE_SECRET_KEY"), host=os.environ.get("LANGFUSE_HOST"))

def load_dataset():
    p = "/var/knowledges/eval/data/golden.csv"
    if os.path.exists(p):
        df = pd.read_csv(p)
        return df.where(pd.notnull(df), None).to_dict(orient="records")
    return []

def _evaluate_agent_criteria(criteria_str: str, result) -> bool:
    """Agentì˜ ë³µí•© ê³¼ì—…(AND ì¡°ê±´, ì •ê·œì‹) ë‹¬ì„± ì—¬ë¶€ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    if not criteria_str: return result.http_status == 200
    for cond in [c.strip() for c in criteria_str.split(" AND ")]:
        if "status_code=" in cond and str(result.http_status) != cond.split("=")[1].strip(): return False
        elif "raw~r/" in cond and not re.search(cond.split("raw~r/")[1].rstrip("/"), result.raw_response): return False
    return True

@pytest.mark.parametrize("case", load_dataset())
def test_eval(case):
    # ID ì¤‘ë³µ ë° ë°ì´í„° ë®ì–´ì“°ê¸° ë°©ì§€ë¥¼ ìœ„í•œ UUID í´ë°±
    cid = case.get("case_id") or str(uuid.uuid4())[:8]
    trace = langfuse.trace(name=f"Eval-{cid}", id=f"{RUN_ID}-{cid}", tags=[RUN_ID, TARGET_TYPE], input=case["input"])
    
    # 1. í†µì‹ 
    res = AdapterRegistry.get_instance(TARGET_TYPE, TARGET_URL).invoke(case["input"])
    trace.update(output=res.to_dict()); trace.score(name="Latency", value=res.latency_ms)
    if res.error: pytest.fail(f"Conn Fail: {res.error}")

    # 2. Fail-Fast
    try: 
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as t: t.write(res.raw_response)
        if subprocess.run(["promptfoo", "eval", "-c", "/var/jenkins_home/scripts/eval_runner/configs/security.yaml", "--prompts", f"file://{t.name}", "-o", "json"], capture_output=True).returncode != 0: raise RuntimeError("ë³´ì•ˆ ì •ì±…(ê¸ˆì¹™ì–´) ìœ„ë°˜")
        if TARGET_TYPE == "http": validate(instance=json.loads(res.raw_response), schema=json.load(open("/var/jenkins_home/scripts/eval_runner/configs/schema.json")))
    except Exception as e: pytest.fail(str(e))

    # 3. Agent íŒë‹¨
    if case.get("target_type") == "agent":
        passed = _evaluate_agent_criteria(case.get("success_criteria", ""), res)
        trace.score(name="TaskCompletion", value=1 if passed else 0)
        assert passed
        return

    # 4. ë¬¸ë§¥ ì‹¬ì¸µ í‰ê°€ (DeepEval)
    judge = GPTModel(model="qwen3-coder:30b", base_url=f"{os.environ.get('OLLAMA_BASE_URL')}/v1")
    tc = LLMTestCase(input=case["input"], actual_output=res.actual_output, expected_output=case.get("expected_output"), retrieval_context=res.retrieval_context)
    mets = [AnswerRelevancyMetric(threshold=0.7, model=judge)]
    
    if case.get("target_type") == "rag":
        # ì›ë¬¸ ëˆ„ë½ ì‹œ ì–µì§€ë¡œ ì±„ì í•˜ì—¬ 0ì  ì²˜ë¦¬ë˜ëŠ” ì˜¤íƒ(Bypass) ë°©ì§€ ë¡œì§
        if res.retrieval_context and len(res.retrieval_context) > 0 and str(res.retrieval_context[0]).strip() != "":
            mets.append(FaithfulnessMetric(threshold=0.8, model=judge))
            if TARGET_TYPE == "http": mets.append(ContextualRecallMetric(threshold=0.8, model=judge))
        else:
            trace.update(metadata={"warning": "ì›ë¬¸(retrieval_context) ë¶€ì¬ë¡œ í™˜ê° í‰ê°€ ìƒëµ"})
    
    for m in mets:
        m.measure(tc)
        trace.score(name=m.__class__.__name__, value=m.score, comment=m.reason)
    assert_test(tc, mets)

```

---

## ì œ6ì¥. Jenkins íŒŒì´í”„ë¼ì¸ ìƒì„± (ìš´ì˜ UI)

ì‚¬ìš©ìê°€ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ Jenkins íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤. API í‚¤ëŠ” ì½”ë“œ ë‚´ í•˜ë“œì½”ë”©ë˜ì§€ ì•Šê³  `withCredentials`ë¥¼ í†µí•´ ì•ˆì „í•˜ê²Œ ì£¼ì…ë©ë‹ˆë‹¤.

1. Jenkins ë¸Œë¼ìš°ì € ë©”ì¸ì—ì„œ **[ìƒˆë¡œìš´ Item]** â” `DSCORE-Universal-Eval` â” **[Pipeline]** ì„ íƒ í›„ OK.
2. í•˜ë‹¨ì˜ Pipeline Script ì…ë ¥ì°½ì— ì•„ë˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ê³  ì €ì¥í•©ë‹ˆë‹¤.

```groovy
pipeline {
    agent any

    // ì‚¬ìš©ì ì…ë ¥ í¼
    parameters {
        string(name: 'TARGET_URL', defaultValue: '', description: 'í‰ê°€ ëŒ€ìƒ URL (ì˜ˆ: http://ëŒ€ìƒ:5000/chat)')
        choice(name: 'TARGET_TYPE', choices: ['http', 'ui_chat'], description: 'í‰ê°€ í†µì‹  ë°©ì‹ ì„ íƒ (API=http, ì›¹ í™”ë©´ ìŠ¤í¬ë˜í•‘=ui_chat)')
        string(name: 'TARGET_AUTH_HEADER', defaultValue: '', description: '(ì„ íƒ) ëŒ€ìƒì´ ì¸ì¦ì„ ìš”êµ¬í•  ê²½ìš° í—¤ë” ê°’ ì…ë ¥ (ì˜ˆ: Bearer YOUR_TOKEN)')
        string(name: 'RESPONSE_JSON_PATH', defaultValue: '$.answer', description: '(API ì „ìš©) ë‹µë³€ì´ ìœ„ì¹˜í•œ JSON Path (ê¸°ë³¸: $.answer)')
        file(name: 'GOLDEN_DATASET', description: 'ë¡œì»¬ PCì˜ í‰ê°€ ì‹œí—˜ì§€(golden.csv) íŒŒì¼ ì—…ë¡œë“œ')
    }

    environment {
        EVAL_DATA_DIR = '/var/knowledges/eval/data'
        EVAL_REPORT_DIR = '/var/knowledges/eval/reports'
        EVAL_SCRIPT_DIR = '/var/jenkins_home/scripts/eval_runner'
        OLLAMA_BASE_URL = "http://host.docker.internal:11434"
        LANGFUSE_HOST = "http://langfuse-server:3000"
    }

    stages {
        stage('1. íŒŒì¼ ì´ë™') {
            steps {
                script {
                    def uploaded = sh(script: "ls golden.csv || echo ''", returnStdout: true).trim()
                    if (uploaded == 'golden.csv') {
                        sh "mv golden.csv ${EVAL_DATA_DIR}/golden.csv"
                    } else {
                        error "[ì‹¤íŒ¨] ì‹œí—˜ì§€ íŒŒì¼ì´ ì²¨ë¶€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    }
                }
            }
        }

        stage('2. íŒŒì´ì¬ í‰ê°€ ì‹¤í–‰') {
            steps {
                // Jenkins Credentialsì— ì €ì¥í•´ë‘” ì•”í˜¸í™”ëœ í‚¤ë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì…í•©ë‹ˆë‹¤.
                withCredentials([
                    string(credentialsId: 'langfuse-public-key', variable: 'LANGFUSE_PUBLIC_KEY'),
                    string(credentialsId: 'langfuse-secret-key', variable: 'LANGFUSE_SECRET_KEY')
                ]) {
                    sh """
                    export PYTHONPATH=${EVAL_SCRIPT_DIR}
                    export OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
                    export TARGET_URL='${params.TARGET_URL}'
                    export TARGET_TYPE='${params.TARGET_TYPE}'
                    export TARGET_AUTH_HEADER='${params.TARGET_AUTH_HEADER}'
                    export RESPONSE_JSON_PATH='${params.RESPONSE_JSON_PATH}'
                    export BUILD_TAG='${env.BUILD_TAG}'
                    
                    # ë°ì´í„° ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì§ë ¬ ì‹¤í–‰
                    python3 -m pytest ${EVAL_SCRIPT_DIR}/tests/test_runner.py --junitxml=${EVAL_REPORT_DIR}/results.xml
                    """
                }
            }
        }

        stage('3. ë¦¬í¬íŠ¸ ê²Œì‹œ') {
            steps { junit "${EVAL_REPORT_DIR}/results.xml" }
        }
    }

    post {
        always {
            script {
                // ë°©ê¸ˆ ì‹¤í–‰í•œ ë‚´ì—­ë§Œ ë°”ë¡œ ë³¼ ìˆ˜ ìˆê²Œ ë”¥ë§í¬ ìƒì„±
                def publicLangfuseUrl = "http://localhost:3000/project/traces?filter=tags%3D${env.BUILD_TAG}"
                currentBuild.description = """
                <div style="padding:15px; border:1px solid #cce5ff; border-radius:5px;">
                    <b>íƒ€ê²Ÿ:</b> ${params.TARGET_URL} (${params.TARGET_TYPE})<br><br>
                    <a href='${publicLangfuseUrl}' target='_blank' style='font-size:16px; font-weight:bold; color:#0056b3;'>
                        ğŸ‘‰ [Langfuse ê´€ì œíƒ‘] ìƒì„¸ ì ìˆ˜, LLM ê°ì  ì‚¬ìœ , ì˜¤ë¥˜ ë¡œê·¸ í™•ì¸
                    </a>
                </div>
                """
            }
        }
    }
}

```

---

## ì œ7ì¥. ì‹¤í–‰ ë° ì¸¡ì • ê²°ê³¼ í™•ì¸ (ì‚¬ìš©ì ê°€ì´ë“œ)

### 7.1 í‰ê°€ ì‹œí—˜ì§€(CSV) ì‘ì„±

ë°”íƒ•í™”ë©´ì— ì—‘ì…€ì´ë‚˜ ë©”ëª¨ì¥ìœ¼ë¡œ `golden.csv`ë¥¼ ë§Œë“­ë‹ˆë‹¤. (IDë¥¼ ë¹„ì›Œë‘ë©´ ì‹œìŠ¤í…œì´ UUIDë¥¼ ìë™ ë¶€ì—¬í•´ ì¶©ëŒì„ ë§‰ì•„ì¤ë‹ˆë‹¤.)

```csv
case_id,target_type,input,expected_output,success_criteria
,rag,í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì˜ ëª©ì ì€?,AI í’ˆì§ˆì˜ ì •ëŸ‰ ê²€ì¦ì…ë‹ˆë‹¤.,

```

### 7.2 íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

1. Jenkinsì—ì„œ **[Build with Parameters]**ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.
2. URL, í†µì‹  ë°©ì‹(http/ui_chat), ì¸ì¦ í—¤ë”(í•„ìš”ì‹œ)ë¥¼ ë„£ê³  ë°”íƒ•í™”ë©´ì˜ `golden.csv`ë¥¼ ì²¨ë¶€í•˜ì—¬ **[Build]** í•©ë‹ˆë‹¤.

### 7.3 ì¸¡ì • ê²°ê³¼ í™•ì¸ì²˜ ìƒì„¸ ë¶„ì„

#### ğŸ“Š í™•ì¸ 1: Jenkins ëŒ€ì‹œë³´ë“œ (Pass/Fail ì§ê´€ì  í™•ì¸)

* ë¹Œë“œ ê²°ê³¼ì˜ `Test Result` íŠ¸ë Œë“œ ê·¸ë˜í”„ë¥¼ ë´…ë‹ˆë‹¤.
* ë§Œì•½ ë¹¨ê°„ìƒ‰ ì‹¤íŒ¨ê°€ ë–´ë‹¤ë©´ `Console Output`ì„ ì—´ì–´ë³´ì‹­ì‹œì˜¤. Promptfoo ê¸ˆì¹™ì–´ ì •ì±… ìœ„ë°˜ì´ë‚˜, JSON ê·œê²© ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ **Fail-Fast** ë°œìƒ ì‹œ ì—¬ê¸°ì— ëª…í™•í•œ ì‚¬ìœ ê°€ ì°í™ë‹ˆë‹¤.

#### ğŸ” í™•ì¸ 2: Langfuse ëŒ€ì‹œë³´ë“œ (ì‹¬ì¸µ ì ìˆ˜ ë° ê°ì  ì‚¬ìœ  ë¶„ì„)

* Jenkins í™”ë©´ ì¤‘ì•™ì— ë‚˜íƒ€ë‚œ **"ğŸ‘‰ [Langfuse ê´€ì œíƒ‘]..."** ë”¥ë§í¬ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.
* ì—´ë¦° í™”ë©´(Traces ë¦¬ìŠ¤íŠ¸)ì—ì„œ í…ŒìŠ¤íŠ¸ í•­ëª©ì„ í•˜ë‚˜ í´ë¦­í•˜ë©´ ë‹¤ìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
1. **ì‘ë‹µ ì†Œìš” ì‹œê°„(Latency)**: ìš°ì¸¡ ìƒë‹¨ì— ë°€ë¦¬ì´ˆ(ms)ë¡œ í‘œê¸°ë©ë‹ˆë‹¤.
2. **ì‹¬ì¸µ ë¬¸ë§¥ ì ìˆ˜(Scores)**: í™”ë©´ ì¤‘ì•™/í•˜ë‹¨ì˜ `Scores` íƒ­ì—ì„œ LLMì´ ì±„ì í•œ `AnswerRelevancy`, `Faithfulness` ì ìˆ˜(0.0~1.0)ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. **ì‹¬íŒê´€ ê°ì  ì‚¬ìœ (Comment)**: í•´ë‹¹ ì ìˆ˜ ìš°ì¸¡ì˜ `Comment` í•„ë“œë¥¼ ì—´ëŒí•˜ì‹­ì‹œì˜¤. ì‹¬íŒê´€ì´ *"ë‹µë³€ ë‚´ìš©ì´ ì˜ë„ì™€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 0.3ì ì„ ë¶€ì—¬í•©ë‹ˆë‹¤"* ì™€ ê°™ì´ ì ì–´ë‘” í‰ê°€ ë¦¬í¬íŠ¸ë¥¼ í†µí•´ AIì˜ í’ˆì§ˆì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.